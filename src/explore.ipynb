{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Trabajaremos con la siguiente base de datos, donde debemos realizar un analisis sobre los comentarios sobre una aplicación, donde debemos poder predecir los comentarios negativos y positivo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "importamos librerias necesarias"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd \n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
                "from sklearn.metrics import classification_report\n",
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
                "from pickle import dump"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Lectura del archivo y verificacion si hay valores faltantes o duplicados\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\")\n",
                "data = data.iloc[:, 1:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 157,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "review      0\n",
                            "polarity    0\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 157,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 158,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 158,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.duplicated().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 159,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>the new features suck for those of us who don...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>forced reload on uploading pic on replying co...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                              review  polarity\n",
                            "0   privacy at least put some option appear offli...         0\n",
                            "1   messenger issues ever since the last update, ...         0\n",
                            "2   profile any time my wife or anybody has more ...         0\n",
                            "3   the new features suck for those of us who don...         0\n",
                            "4   forced reload on uploading pic on replying co...         0"
                        ]
                    },
                    "execution_count": 159,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Separamos los datos y y los vectorizamos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 160,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(data[\"review\"], data[\"polarity\"], test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 161,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = CountVectorizer(stop_words=\"english\")\n",
                "X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
                "X_test_vec = vectorizer.transform(X_test).toarray()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 162,
            "metadata": {},
            "outputs": [],
            "source": [
                "sorter = MultinomialNB().fit(X_train_vec,y_train)         \n",
                "\n",
                "y_pred = sorter.predict(X_test_vec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 163,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.90      0.87       126\n",
                        "           1       0.73      0.60      0.66        53\n",
                        "\n",
                        "    accuracy                           0.82       179\n",
                        "   macro avg       0.79      0.75      0.77       179\n",
                        "weighted avg       0.81      0.82      0.81       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 164,
            "metadata": {},
            "outputs": [],
            "source": [
                "gaus = GaussianNB().fit(X_train_vec,y_train)\n",
                "\n",
                "y_pred = gaus.predict(X_test_vec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 165,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.85      0.88      0.86       126\n",
                        "           1       0.69      0.62      0.65        53\n",
                        "\n",
                        "    accuracy                           0.80       179\n",
                        "   macro avg       0.77      0.75      0.76       179\n",
                        "weighted avg       0.80      0.80      0.80       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 166,
            "metadata": {},
            "outputs": [],
            "source": [
                "bearn = BernoulliNB().fit(X_train_vec,y_train)\n",
                "\n",
                "y_pred = bearn.predict(X_test_vec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 167,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.79      0.93      0.85       126\n",
                        "           1       0.70      0.40      0.51        53\n",
                        "\n",
                        "    accuracy                           0.77       179\n",
                        "   macro avg       0.74      0.66      0.68       179\n",
                        "weighted avg       0.76      0.77      0.75       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 174,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 200 is smaller than n_iter=400. Running 200 iterations. For exhaustive searches, use GridSearchCV.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mejores hiperparámetros: {'fit_prior': False, 'alpha': 0.31272727272727274}\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.87      0.89      0.88       126\n",
                        "           1       0.72      0.68      0.70        53\n",
                        "\n",
                        "    accuracy                           0.83       179\n",
                        "   macro avg       0.79      0.78      0.79       179\n",
                        "weighted avg       0.82      0.83      0.83       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "param_grid = {\n",
                "    \"alpha\": np.linspace(0.01, 10.0, 100),\n",
                "    \"fit_prior\": [True, False]\n",
                "}\n",
                "\n",
                "grid_search = RandomizedSearchCV(sorter, param_grid, cv=5, scoring='recall', n_jobs=-1, n_iter=400, random_state=42)\n",
                "\n",
                "grid_search.fit(X_train_vec, y_train)\n",
                "\n",
                "best_params = grid_search.best_params_\n",
                "\n",
                "print(\"Mejores hiperparámetros:\", best_params)\n",
                "\n",
                "y_pred = grid_search.predict(X_test_vec)\n",
                "\n",
                "print(classification_report(y_test, y_pred))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 175,
            "metadata": {},
            "outputs": [],
            "source": [
                "direccion = \"/workspaces/Naive_bayes/models/mi_modelo.sav\"\n",
                "dump(sorter, open(direccion, 'wb'))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conclusión : \n",
                "\n",
                "    Pudimos determinar que el mejor modelo es el modelo Multinomial, el cual nos arrojo la siguiente información.\n",
                "\n",
                "    º Para la Clase 0 (Comentarios Negativos):\n",
                "\n",
                "        - Precisión (Precision): 87% de los comentarios clasificados como negativos fueron realmente negativos.\n",
                "\n",
                "        - Exhaustividad (Recall): De todos los comentarios negativos reales, el modelo identificó correctamente el 89% de ellos.\n",
                "\n",
                "        - Puntuación F1: La puntuación F1 es una combinación de precisión y recall, proporcionando un equilibrio. En este caso, es 88%.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "Para la Clase 1 (Comentarios Positivos):\n",
                "\n",
                "        - Precisión (Precision): 72% de los comentarios clasificados como positivos fueron realmente positivos.\n",
                "\n",
                "        - Exhaustividad (Recall): De todos los comentarios positivos reales, el modelo identificó correctamente el 68% de ellos.\n",
                "        \n",
                "        - Puntuación F1: La puntuación F1 para comentarios positivos es 70%.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "Interpretación General:\n",
                "\n",
                "La precisión es alta para los comentarios negativos, lo que significa que cuando el modelo dice que un comentario es negativo, tiende a ser correcto en un 87% de las veces.\n",
                "La exhaustividad es un poco más alta para los comentarios negativos (89%), lo que indica que el modelo identifica la mayoría de los comentarios negativos reales.\n",
                "Para los comentarios positivos, tanto la precisión como la exhaustividad son un poco más bajas (72% y 68%, respectivamente), lo que sugiere que hay más margen de mejora en la identificación de comentarios positivos."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
