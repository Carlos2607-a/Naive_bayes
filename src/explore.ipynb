{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Trabajaremos con la siguiente base de datos, donde debemos realizar un analisis sobre los comentarios sobre una aplicaci√≥n, donde debemos poder predecir los comentarios negativos y positivo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "importamos librerias necesarias"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd \n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
                "from sklearn.metrics import classification_report\n",
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
                "from pickle import dump"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Lectura del archivo y verificacion si hay valores faltantes o duplicados\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\")\n",
                "data = data.iloc[:, 1:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 157,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "review      0\n",
                            "polarity    0\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 157,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 158,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 158,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.duplicated().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 159,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>the new features suck for those of us who don...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>forced reload on uploading pic on replying co...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                              review  polarity\n",
                            "0   privacy at least put some option appear offli...         0\n",
                            "1   messenger issues ever since the last update, ...         0\n",
                            "2   profile any time my wife or anybody has more ...         0\n",
                            "3   the new features suck for those of us who don...         0\n",
                            "4   forced reload on uploading pic on replying co...         0"
                        ]
                    },
                    "execution_count": 159,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Separamos los datos y y los vectorizamos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 160,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(data[\"review\"], data[\"polarity\"], test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 161,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = CountVectorizer(stop_words=\"english\")\n",
                "X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
                "X_test_vec = vectorizer.transform(X_test).toarray()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 162,
            "metadata": {},
            "outputs": [],
            "source": [
                "sorter = MultinomialNB().fit(X_train_vec,y_train)         \n",
                "\n",
                "y_pred = sorter.predict(X_test_vec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 163,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.90      0.87       126\n",
                        "           1       0.73      0.60      0.66        53\n",
                        "\n",
                        "    accuracy                           0.82       179\n",
                        "   macro avg       0.79      0.75      0.77       179\n",
                        "weighted avg       0.81      0.82      0.81       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 164,
            "metadata": {},
            "outputs": [],
            "source": [
                "gaus = GaussianNB().fit(X_train_vec,y_train)\n",
                "\n",
                "y_pred = gaus.predict(X_test_vec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 165,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.85      0.88      0.86       126\n",
                        "           1       0.69      0.62      0.65        53\n",
                        "\n",
                        "    accuracy                           0.80       179\n",
                        "   macro avg       0.77      0.75      0.76       179\n",
                        "weighted avg       0.80      0.80      0.80       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 166,
            "metadata": {},
            "outputs": [],
            "source": [
                "bearn = BernoulliNB().fit(X_train_vec,y_train)\n",
                "\n",
                "y_pred = bearn.predict(X_test_vec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 167,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.79      0.93      0.85       126\n",
                        "           1       0.70      0.40      0.51        53\n",
                        "\n",
                        "    accuracy                           0.77       179\n",
                        "   macro avg       0.74      0.66      0.68       179\n",
                        "weighted avg       0.76      0.77      0.75       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 174,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 200 is smaller than n_iter=400. Running 200 iterations. For exhaustive searches, use GridSearchCV.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mejores hiperpar√°metros: {'fit_prior': False, 'alpha': 0.31272727272727274}\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.87      0.89      0.88       126\n",
                        "           1       0.72      0.68      0.70        53\n",
                        "\n",
                        "    accuracy                           0.83       179\n",
                        "   macro avg       0.79      0.78      0.79       179\n",
                        "weighted avg       0.82      0.83      0.83       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "param_grid = {\n",
                "    \"alpha\": np.linspace(0.01, 10.0, 100),\n",
                "    \"fit_prior\": [True, False]\n",
                "}\n",
                "\n",
                "grid_search = RandomizedSearchCV(sorter, param_grid, cv=5, scoring='recall', n_jobs=-1, n_iter=400, random_state=42)\n",
                "\n",
                "grid_search.fit(X_train_vec, y_train)\n",
                "\n",
                "best_params = grid_search.best_params_\n",
                "\n",
                "print(\"Mejores hiperpar√°metros:\", best_params)\n",
                "\n",
                "y_pred = grid_search.predict(X_test_vec)\n",
                "\n",
                "print(classification_report(y_test, y_pred))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 175,
            "metadata": {},
            "outputs": [],
            "source": [
                "direccion = \"/workspaces/Naive_bayes/models/mi_modelo.sav\"\n",
                "dump(sorter, open(direccion, 'wb'))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conclusi√≥n : \n",
                "\n",
                "    Pudimos determinar que el mejor modelo es el modelo Multinomial, el cual nos arrojo la siguiente informaci√≥n.\n",
                "\n",
                "    ¬∫ Para la Clase 0 (Comentarios Negativos):\n",
                "\n",
                "        - Precisi√≥n (Precision): 87% de los comentarios clasificados como negativos fueron realmente negativos.\n",
                "\n",
                "        - Exhaustividad (Recall): De todos los comentarios negativos reales, el modelo identific√≥ correctamente el 89% de ellos.\n",
                "\n",
                "        - Puntuaci√≥n F1: La puntuaci√≥n F1 es una combinaci√≥n de precisi√≥n y recall, proporcionando un equilibrio. En este caso, es 88%.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "Para la Clase 1 (Comentarios Positivos):\n",
                "\n",
                "        - Precisi√≥n (Precision): 72% de los comentarios clasificados como positivos fueron realmente positivos.\n",
                "\n",
                "        - Exhaustividad (Recall): De todos los comentarios positivos reales, el modelo identific√≥ correctamente el 68% de ellos.\n",
                "        \n",
                "        - Puntuaci√≥n F1: La puntuaci√≥n F1 para comentarios positivos es 70%.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "Interpretaci√≥n General:\n",
                "\n",
                "La precisi√≥n es alta para los comentarios negativos, lo que significa que cuando el modelo dice que un comentario es negativo, tiende a ser correcto en un 87% de las veces.\n",
                "La exhaustividad es un poco m√°s alta para los comentarios negativos (89%), lo que indica que el modelo identifica la mayor√≠a de los comentarios negativos reales.\n",
                "Para los comentarios positivos, tanto la precisi√≥n como la exhaustividad son un poco m√°s bajas (72% y 68%, respectivamente), lo que sugiere que hay m√°s margen de mejora en la identificaci√≥n de comentarios positivos."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
